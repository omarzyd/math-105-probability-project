# -*- coding: utf-8 -*-
"""Prob  Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rohWBBAcLMenrjQBAJcRxrPKtcjAKP-H

#Math 105 Project

Impoting The Essential Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from math import comb
!pip install deap
from deap import base, creator, tools, algorithms
import random

"""#Data Cleaning

"""

math_data = pd.read_csv('/content/student-mat.csv', sep=';')
portuguese_data = pd.read_csv('/content/student-por.csv', sep=';')

# Display first few rows of the math dataset to understand its structure
print(math_data.head())

print("Missing values in the math dataset:")
print(math_data.isnull().sum())  # Check for missing values

# Convert Categorical Data to Numeric
math_data['sex'] = math_data['sex'].map({'F': 0, 'M': 1})
math_data['school'] = math_data['school'].map({'GP': 0, 'MS': 1})
math_data['address'] = math_data['address'].map({'U': 0, 'R': 1})
math_data['famsize'] = math_data['famsize'].map({'LE3': 0, 'GT3': 1})
math_data['Pstatus'] = math_data['Pstatus'].map({'T': 0, 'A': 1})
math_data['schoolsup'] = math_data['schoolsup'].map({'yes': 1, 'no': 0})
math_data['famsup'] = math_data['famsup'].map({'yes': 1, 'no': 0})
math_data['paid'] = math_data['paid'].map({'yes': 1, 'no': 0})
math_data['activities'] = math_data['activities'].map({'yes': 1, 'no': 0})
math_data['nursery'] = math_data['nursery'].map({'yes': 1, 'no': 0})
math_data['higher'] = math_data['higher'].map({'yes': 1, 'no': 0})
math_data['internet'] = math_data['internet'].map({'yes': 1, 'no': 0})
math_data['romantic'] = math_data['romantic'].map({'yes': 1, 'no': 0})

# Check the data types after conversion
print(math_data.dtypes)

"""#Data Exploration (Summary and Visualizations)"""

#Summary Statistics for Grades (G1, G2, G3)
grades_summary = math_data[['G1', 'G2', 'G3']].describe()
print(grades_summary)

# Mean, Median, and Standard Deviation of Grades (G1, G2, G3)
mean_g1 = math_data['G1'].mean()
median_g1 = math_data['G1'].median()
std_g1 = math_data['G1'].std()

mean_g2 = math_data['G2'].mean()
median_g2 = math_data['G2'].median()
std_g2 = math_data['G2'].std()

mean_g3 = math_data['G3'].mean()
median_g3 = math_data['G3'].median()
std_g3 = math_data['G3'].std()

# Print mean, median, and standard deviation
print(f"Grade 1 (G1) - Mean: {mean_g1}, Median: {median_g1}, Std Dev: {std_g1}")
print(f"Grade 2 (G2) - Mean: {mean_g2}, Median: {median_g2}, Std Dev: {std_g2}")
print(f"Final Grade (G3) - Mean: {mean_g3}, Median: {median_g3}, Std Dev: {std_g3}")

#Distribution of Grades (G1, G2, G3)
plt.figure(figsize=(10, 6))
sns.histplot(math_data['G3'], kde=True, color='blue')
plt.title('Distribution of Final Grades (G3)')
plt.xlabel('Grade')
plt.ylabel('Frequency')
plt.show()

#Correlation Heatmap (Only numeric columns)
numeric_data = math_data.select_dtypes(include=[np.number])  # Select only numeric columns

corr_matrix = numeric_data.corr()

plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix of Numeric Features')
plt.show()

# Relationship between Study Time and Final Grade (G3)
plt.figure(figsize=(10, 6))
sns.scatterplot(x='studytime', y='G3', data=math_data, color='green')
plt.title('Study Time vs Final Grade (G3)')
plt.xlabel('Study Time')
plt.ylabel('Final Grade (G3)')
plt.show()

# Boxplot of Mother's Education vs Final Grade
plt.figure(figsize=(10, 6))
sns.boxplot(x='Medu', y='G3', data=math_data)
plt.title('Mother’s Education vs Final Grade (G3)')
plt.xlabel('Mother’s Education')
plt.ylabel('Final Grade (G3)')
plt.show()

# Bar Plot: Gender vs Final Grade
plt.figure(figsize=(10, 6))
sns.barplot(x='sex', y='G3', data=math_data, palette='Set2')
plt.title('Gender vs Final Grade (G3)')
plt.xlabel('Gender')
plt.ylabel('Final Grade (G3)')
plt.show()

"""#Statistical Analysis"""

# Gender vs Final Grade (G3)
grouped_gender = math_data.groupby('sex')['G3']
male_grades = grouped_gender.get_group(1)
female_grades = grouped_gender.get_group(0)
t_stat_gender, p_value_gender = stats.ttest_ind(male_grades, female_grades)
print(f"Gender vs Final Grade T-test: T-statistic: {t_stat_gender}, P-value: {p_value_gender}")
# Interpretation of Gender T-test
if p_value_gender < 0.05:
    print("We reject the null hypothesis: Gender has a significant effect on grades.")
else:
    print("We fail to reject the null hypothesis: Gender does not have a significant effect on grades.")

# Mother's Education vs Final Grade (G3)
higher_education = math_data[math_data['Medu'] == 4]  # Mother with higher education
other_education = math_data[math_data['Medu'] != 4]  # Mother without higher education
t_stat_med, p_value_med = stats.ttest_ind(higher_education['G3'], other_education['G3'])
print(f"Mother's Education vs Final Grade T-test: T-statistic: {t_stat_med}, P-value: {p_value_med}")

# Interpretation of Mother's Education T-test
if p_value_med < 0.05:
    print("We reject the null hypothesis: Mother's education has a significant effect on grades.")
else:
    print("We fail to reject the null hypothesis: Mother's education does not have a significant effect on grades.")

"""#Probability Analysis"""

# Covariance and Correlation Analysis
def show_cov_corr():
    # Calculate covariance and correlation between relevant columns
    covariance = math_data['studytime'].cov(math_data['G3'])  # Covariance between studytime and final grade
    correlation = math_data['studytime'].corr(math_data['G3'])  # Correlation between studytime and final grade
    result_text = f"Covariance and Correlation:\nCovariance: {covariance:.2f}\nCorrelation: {correlation:.2f}"
    print(result_text)

show_cov_corr()

# Skewness Analysis
def show_skewness():
    # Skewness of relevant columns
    skew_g1 = stats.skew(math_data['G1'])  # Skewness of first period grades
    skew_g2 = stats.skew(math_data['G2'])  # Skewness of second period grades
    skew_g3 = stats.skew(math_data['G3'])  # Skewness of final grades

    def skewness_type(skew):
        if skew > 0:
            return "Right Skewed"
        elif skew < 0:
            return "Left Skewed"
        else:
            return "Symmetric"

    result_text = (f"Skewness:\nSkewness (G1): {skew_g1:.2f} - {skewness_type(skew_g1)}\n"
                   f"Skewness (G2): {skew_g2:.2f} - {skewness_type(skew_g2)}\n"
                   f"Skewness (G3): {skew_g3:.2f} - {skewness_type(skew_g3)}")
    print(result_text)
show_skewness()

# Binomial Distribution Example (For Grades)
p = 0.6  # Probability of success (e.g., probability of achieving G3 >= 10)
n = 20  # Number of trials (total grade points, as an example)
x = 10  # Number of successes (students passing)

# Binomial Distribution - Calculate the binomial coefficient and probability of exactly x successes (G3 >= 10)
binomial_coefficient = comb(n, x)  # Calculate the binomial coefficient (n choose x)
binomial_prob = binomial_coefficient * (p ** x) * ((1 - p) ** (n - x))
print(f"Binomial Distribution (P(X=10)): {binomial_prob:.4f}")

# Cumulative distribution (P(X <= 10)) using binomial formula
binomial_cdf = sum(comb(n, k) * (p ** k) * ((1 - p) ** (n - k)) for k in range(x + 1))
print(f"Cumulative Distribution (P(X <= 10)): {binomial_cdf:.4f}")

"""#Machine Learning Model

"""

# Select relevant features for optimization
features = ['studytime', 'activities', 'famsup', 'internet', 'romantic', 'G3']
data = math_data[features]

# Normalize the data
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data[['studytime', 'activities', 'famsup', 'internet', 'romantic']])

# Add the scaled features back to the dataframe
data[['studytime', 'activities', 'famsup', 'internet', 'romantic']] = data_scaled

# Define the multi-objective optimization problem
# Objective 1: Maximize G3 (final grade)
# Objective 2: Maximize engagement in extracurricular activities (e.g., studytime, activities, school support)
def fitness(individual):
    studytime, activities, famsup, internet, romantic = individual
    academic_success = 20 - abs(data['G3'].mean() - (studytime * 0.5 + activities * 0.3 + famsup * 0.1 + internet * 0.1))
    extracurricular_engagement = activities * 0.4 + studytime * 0.3 + famsup * 0.2 + romantic * 0.1

    # Return two objectives: maximize academic success and extracurricular engagement
    return (academic_success, extracurricular_engagement)

# Define the problem as a multi-objective problem in DEAP
creator.create("FitnessMulti", base.Fitness, weights=(1.0, 1.0))  # Maximize both objectives
creator.create("Individual", list, fitness=creator.FitnessMulti)

# Create an individual (solution) with random values
def create_individual():
    return [random.uniform(0, 1) for _ in range(5)]  # 5 features: studytime, activities, famsup, internet, romantic

# Register components for genetic algorithm
toolbox = base.Toolbox()
toolbox.register("individual", tools.initIterate, creator.Individual, create_individual)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)
toolbox.register("mate", tools.cxBlend, alpha=0.5)
toolbox.register("mutate", tools.mutGaussian, mu=0.0, sigma=1.0, indpb=0.2)
toolbox.register("select", tools.selNSGA2)  # Use NSGA-II for multi-objective optimization
toolbox.register("evaluate", fitness)

# Create a population of 100 individuals (solutions)
population = toolbox.population(n=100)

# Parameters for the algorithm
number_of_generations = 50
crossover_probability = 0.7
mutation_probability = 0.2
elitism = 2  # Elite individuals that survive to the next generation

# Run the genetic algorithm
for gen in range(number_of_generations):
    offspring = toolbox.select(population, len(population))
    offspring = list(map(toolbox.clone, offspring))

    # Apply crossover and mutation
    for child1, child2 in zip(offspring[::2], offspring[1::2]):
        if random.random() < crossover_probability:
            toolbox.mate(child1, child2)
            del child1.fitness.values
            del child2.fitness.values

    for mutant in offspring:
        if random.random() < mutation_probability:
            toolbox.mutate(mutant)
            del mutant.fitness.values

    # Evaluate the individuals with invalid fitness
    invalid_individuals = [ind for ind in offspring if not ind.fitness.valid]
    fitnesses = map(toolbox.evaluate, invalid_individuals)
    for ind, fit in zip(invalid_individuals, fitnesses):
        ind.fitness.values = fit

    # Apply elitism: keep the best individuals
    population[:] = offspring[:]
    population.extend(tools.selBest(population, elitism))  # Keep elite individuals

    # Output the current generation's statistics
    fits = [ind.fitness.values for ind in population]
    lengths = [len(ind) for ind in population]
    print(f"Generation {gen}: Best fitness: {max(fits)}")

# Extract the objectives for visualization
front = tools.sortNondominated(population, len(population), first_front_only=True)[0]
academic_success = [ind.fitness.values[0] for ind in front]
extracurricular_engagement = [ind.fitness.values[1] for ind in front]

# Plot the Pareto front
plt.figure(figsize=(10, 6))
plt.scatter(academic_success, extracurricular_engagement, color="blue")
plt.title("Pareto Front: Academic Success vs. Extracurricular Engagement")
plt.xlabel("Academic Success (G3 prediction)")
plt.ylabel("Extracurricular Engagement (Study + Activities)")
plt.grid(True)
plt.show()